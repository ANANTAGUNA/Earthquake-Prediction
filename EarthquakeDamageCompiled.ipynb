{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><center>Richter's Predictor: Modeling Earthquake Damage</center></h2>\n",
    "<img style=\"height:300px\" src=\"earthquake.jpg\">\n",
    "<h4><center>Contributors: Naman Bhargava, Neeraj Alavala, Vidhur Kumar, Jordan Rodrigues</center><h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Within the United States alone, earthquakes destroy nearly $4.4B of economic value yearly. Across the world, countless individuals perish from earthquakes yearly. Using machine learning, the damage caused by earthquakes can be better anticipated, allowing for preventative measures that can help mitigate both the lethality and destructiveness of earthquakes.\n",
    "\n",
    "Our team will be delving into the 2015 Nepal Earthquake Open Data Portal. This data, which was collected using mobile devices following the Gorkha Earthquake of April 2015, details the level of destruction brought upon more than 200,000 buildings in the area. By utilizing various features reported by Nepali citizens (such as building size, purpose, and construction material), we will construct a machine learning classifier capable of determining the extent to which a building would be damaged in a future earthquake. \n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration & Preprocessing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>Our initial approach was to scan for data imbalance, search for NaN values, and visualize the distributions of various features as well as the degree to which they correlation with the value we were trying to predict (damage grade).</center>\n",
    "<br>\n",
    "<center><img style=\"height:500px\" src=\"Correlation.png\"></center>\n",
    "\n",
    "<h5>Upon initial visualization, it becomes clear that this isn't a very highly predictive dataset. At most, the correlation of any given variable is +/- 0.2. In other words, it will likely be difficult to accurately classify the damage grades</h5>\n",
    "\n",
    "<h5> In the initial data, we were also given a few categorical variables. These included land condition, roof type, floor type, legal status, and more. We used one-hot encoding to allow for models to be trained on this non-integer data. Fortunately, this data did not have any null values, so imputation was not necessary. </h5> \n",
    "\n",
    "<h5>In terms of the data balance, the data is roughly imbalanced towards damage grade 2. However, it is not severe enough to have to add any special sampling techniques for the minority classes (in this case, damage 1). </h5>\n",
    "<img style=\"height:300px\" src=\"piechart_lul.png\">\n",
    "\n",
    "<h5>Of the 38-feature dataset, 8 of the features were categorical. One-hot encoding was used to transform these categorical features into various binary featuresm prior to training any models.</h5>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data has been collected for us, but we plan to spend a significant amount of time preparing (cleaning, encoding, etc) the data for the model. We will also perform meaningful visualizations to better understand the relationships between our features. We will run a variety of classifiers (as listed below) to best identify damage caused by earthquakes. The hyperparameters will be tuned using the GridSearchCV process. The model performances will be compared  by micro averaged F1 score, which will balance precision and recall modified to gauge accuracy for classification into 3 categories.\n",
    "\n",
    "#### Classifiers\n",
    " - Multiple Logistic regression\n",
    " - Support vector regression\n",
    " - Kmeans\n",
    " - DBSCAN\n",
    " - PCA\n",
    " - LDA\n",
    " - Cross validation\n",
    " - Hybrid Neural Network\n",
    " - Decision Tree\n",
    " - Random Forest Decision Tree\n",
    " - XGBoost Decision Tree\n",
    " (add plots under section option)\n",
    " \n",
    " <hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Expected Results\n",
    "\n",
    "Given the relatively low correlation between the features and the variable we're trying to predict (damage_grade) as well as the fact that the current leaderboard accuracy for this competition is 0.75 accuracy, our group would hope to achieve around ~0.7 accuracy. We assume that an ensemble will produce the highest quality results while KMeans/DBSCAN while produce the lowest quality results as the data likely is not centric / low-dimensional.\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PCA\n",
    "\n",
    "PCA was initially conducted to get a visual feel for how seperable the data was if we only focused on low-dimensionality. Min-max normalization was confucted on the data prior to running PCA. Unfortunately, in a two and three dimensional space, there were no clear separating bounds that could be visualized. Given that our data was ~38 dimensions, this meant that dimensionality reduction failed to be an effective technique\n",
    "\n",
    "<center><img style=\"height:600px\" src=\"2DPca.png\"><img style=\"height:600px\" src=\"3DPCA.png\"></center>\n",
    "\n",
    "## LDA\n",
    "\n",
    "Next, we attempted to use LDA. We hoped that using a supervised linear transformation technique would produce greater separability in the data. While this did perform better than the PCA, it only did marginally better. It is also important to note that while the layers do appeared to be \"stacked\" on top of each other, this is not the result of any 3D Separability -- matplotlib just places new points on top of old ones, and points were graphed one class at a time.\n",
    "\n",
    "<center><img style=\"height:600px;width:500px\" src=\"LDA.png\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DBSCAN & KMEANS\n",
    "\n",
    "Tried DBSCAN, but with the high dimensionality of the data (39 features with one-hot encoding) it was very difficult to get greater than 0 clusters unless the epsilon parameter was very high. In order to achieve some clusters the epsilon value had to be greater than 40 even with just a minpts of 3. Anything below that epsilon would result in 0 clusters. After trying some more variants of eps, a trial using an eps of 42, minpts of 3 and euclidian distance as the metric, we were able to get 3 clusters\n",
    "\n",
    "Tried KMEANS while setting the number of n_clusters to 3 in hopes of clustering them close to damage grade. Just like with DBSCAN it seems KMEANS clustering does not perform well either with high dimensional data. KMEANS was able to provide an output of each datapoint to one of 3 clusters but after comparing all variations of cluster assignments to damage grade, the maximum accuracy we got was 33.5%."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There were 4 different types of decision trees that were evaluated including normal decision trees, random forest, extreme gradient boosting, and lite gradient boosting. Using the one-hot encoded data to convert categorical data into numerical data and 5-fold cross validation, a small version of each type of tree was created to compare their effectiveness by the F1 score metric. \n",
    "\n",
    "<img src=\"source_images/baseline_tree_comp.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results from the initial F1 score comparison demonstrate that random forest, extreme gradient boosting, and lite gradient boosting are more promising than the normal decision tree. The normal decision tree had already started overfitting the data since its train accuracy is significantly higher than its validation accuracy. Due to this overfitting, normal decision trees were not explored farther."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest\n",
    "\n",
    "Random forest decision trees reduce the variance in decision trees since they specify random feature subsets and build and combine many small trees. To make a prediction, random forest trees will either take the prediciton with the highest probability or average the predictions made by its smaller trees. By increasing the number of trees in the forest, both the training and validation accuracy increase due to the smaller tree averages converging on the true trends in the data. This is the idea of ensemble learning which is revisited later in the decision tree exploration."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extreme Gradient Boosting\n",
    "\n",
    "Extreme gradient boosting also is composed of a set of decision trees but is built by training a tree to add to the forest. Instead of using an average or max of the probabilities from its trees while making predictions, extreme gradient boosting combines the tree prediciton results sequentially (Glen). Increasing the number of trees in the forest also improves the accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lite Gradient Boosting\n",
    "\n",
    "Lite gradient boosting is also a gradient boosting framework, however it builds its trees by adding to leaves instead of adding levels.\n",
    "<center>\n",
    "<img src=\"source_images/leafwisegrowth.png\" style=\"width:800px;\">\n",
    "(Mandot)\n",
    "<img src=\"source_images/levelwisegrowth.png\" style=\"width:800px;\">\n",
    "(Mandot)\n",
    "</center>\n",
    "\n",
    "This architecture is highly dependent on the number of leaves it expands. More leaves allow it to fit data better, but also can cause overfitting. This architecture can also be used with ensemble learning, and adding more trees will increase the accuracy. The results from the baseline accuracy tree test indicate that the tree should be made to fit the training data better since the train and validation accuracies were very similar. A comparison of the F1 score validation accuracies with varying the number of leaves is shown below.\n",
    "\n",
    "<img src=\"source_images/num_leaves_analysis.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The comparison of number of leaves above reveals that the optimal number of trees is 80. While evaluating the optimal number of trees, the F1 score constantly increases with diminishing reward. However, as the number of trees increases, the training time increases. 3,000 was the final number of trees selected.\n",
    "\n",
    "The validation accuracy of using one decision plateaued around 0.73, however by taking the idea of an ensemble from random forests and applying it to the tuned lightGBM and the extreme gradient boosting frameworks, the final validation accuracy was 0.7462. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The overall results from tuning are shown in the plot below.\n",
    "\n",
    "<img src=\"source_images/tuned_tree_comp.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This plot shows that the lite gradient boosting was the best technique at the end of the tuning done in this analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AutoML: \n",
    "\n",
    "AutoML was utilized as a benchmark test to see if Microsoft Azure's \"Automatic ML\" classification would provide useful. One simply uploads the data, specifies the type of task they are seeking to perform (classification, in our case), and then Azure runs various ML algorithms on it with the purpose of optimizing performance. The results were equally poor with a lot of our previous testing, as visualized below.\n",
    "\n",
    "<center><img style=\"width:420px\" src=\"AutoML.png\"></center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a whole, our classification model performed better than expected. While we initially struggled with various common types of classification (KMeans, DBScan, PCA, LDA), we eventually found success in the form of an ensemble using the litegbm framework. The random forest decision tree demonstrated the advantage of ensembles. While trying extreme gradient boosting, we discovered lightGBM, a gradient boosting framework that builds trees by expanding leaves. This allowed the ensemble decision tree to converge faster and had better success after tuning the number of leaves expanded. The best results were a result of an ensemble of lightGBM trees. Overall, we were fairly satisfied with our performance. \n",
    "\n",
    "<img style=\"height:350px\" src=\"Competition.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Asim, K. M., Idris, A., Iqbal, T., & Martínez-Álvarez, F. (2018). Earthquake prediction model using support vector regressor and hybrid neural networks. Plos One, 13(7). doi: 10.1371/journal.pone.0199004\n",
    "\n",
    "DrivenData. (n.d.). Richter's Predictor: Modeling Earthquake Damage. Retrieved September 28, 2019, from https://www.drivendata.org/competitions/57/nepal-earthquake/page/136/\n",
    "\n",
    "Glen, Stephanie. “Decision Tree vs Random Forest vs Gradient Boosting Machines: Explained Simply.” Data Science Central, 28 July 2019, www.datasciencecentral.com/profiles/blogs/decision-tree-vs-random-forest-vs-boosted-trees-explained.\n",
    "\n",
    "Ji, M., Liu, L., & Buchroithner, M. (2018). Identifying Collapsed Buildings Using Post-Earthquake Satellite Imagery and Convolutional Neural Networks: A Case Study of the 2010 Haiti Earthquake. Remote Sensing, 10(11), 1689. https://doi.org/10.3390/rs10111689\n",
    "\n",
    "Mandot, Pushkar. “What Is LightGBM, How to Implement It? How to Fine Tune the Parameters?” Medium, Medium, 1 Dec. 2018, medium.com/@pushkarmandot/https-medium-com-pushkarmandot-what-is-lightgbm-how-to-implement-it-how-to-fine-tune-the-parameters-60347819b7fc.\n",
    "\n",
    "Rouet‐Leduc, B.,  Hulbert, C.,  Lubbers, N.,  Barros, K.,  Humphreys, C. J., &  Johnson, P. A. ( 2017).  Machine learning predicts laboratory earthquakes. Geophysical Research Letters,  44,  9276– 9282. https://doi.org/10.1002/2017GL074677 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
